{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e354e8-e574-42e0-8e1e-d1fb9642f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "print(\"üì• √âtape 1 : Chargement du dataset...\")\n",
    "df = pd.read_csv(r\"C:\\Users\\Utilisateur\\Desktop\\IntroductionRecherche\\Dataset\\metahateNetoye.csv\")\n",
    "df = df[['label', 'text']]\n",
    "\n",
    "print(\"‚öñÔ∏è √âtape 2 : √âquilibrage des classes par oversampling...\")\n",
    "max_class_size = df['label'].value_counts().max()\n",
    "df = df.groupby('label').apply(lambda x: x.sample(max_class_size, replace=True, random_state=42)).reset_index(drop=True)\n",
    "print(\"‚úîÔ∏è Classes √©quilibr√©es :\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(\"üßπ √âtape 3 : Suppression des tweets vides...\")\n",
    "df = df[df['text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "print(f\"Nombre de tweets apr√®s nettoyage : {len(df)}\")\n",
    "\n",
    "print(\"üìä √âtape 4 : Visualisation de la r√©partition des classes...\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title(\"üìä R√©partition des classes dans le dataset (apr√®s √©quilibrage)\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üß† √âtape 5 : Vectorisation des textes (CountVectorizer)...\")\n",
    "vectorizer = CountVectorizer(max_features=700000)\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['label']\n",
    "print(f\"‚úÖ Shape des donn√©es vectoris√©es : {X.shape}\")\n",
    "\n",
    "print(\"üìÇ √âtape 6 : D√©coupage en jeu d'entra√Ænement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"‚úîÔ∏è Taille du jeu d'entra√Ænement : {X_train.shape[0]}\")\n",
    "print(f\"‚úîÔ∏è Taille du jeu de test : {X_test.shape[0]}\")\n",
    "\n",
    "print(\"ü§ñ √âtape 7 : Entra√Ænement du mod√®le (Logistic Regression)...\")\n",
    "model = LogisticRegression(\n",
    "    C=1000.0,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    max_iter=2000,\n",
    "    class_weight='balanced',\n",
    "    multi_class='multinomial',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©.\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# === Calcul des m√©triques globales ===\n",
    "accuracy_global = accuracy_score(y_test, y_pred)\n",
    "precision_global = precision_score(y_test, y_pred, average='macro')\n",
    "recall_global = recall_score(y_test, y_pred, average='macro')\n",
    "f1_macro_global = f1_score(y_test, y_pred, average='macro')\n",
    "f1_micro_global = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# === Calcul des m√©triques par classe ===\n",
    "classes = np.unique(y_test)\n",
    "metrics_by_class = []\n",
    "\n",
    "for cls in classes:\n",
    "    # Filtrer les donn√©es pour la classe actuelle\n",
    "    idx_cls = (y_test == cls)\n",
    "    acc_cls = accuracy_score(y_test[idx_cls], y_pred[idx_cls])\n",
    "    precision_cls = precision_score(y_test, y_pred, labels=[cls], average='macro', zero_division=0)\n",
    "    recall_cls = recall_score(y_test, y_pred, labels=[cls], average='macro', zero_division=0)\n",
    "    f1_macro_cls = f1_score(y_test, y_pred, labels=[cls], average='macro', zero_division=0)\n",
    "    f1_micro_cls = f1_score(y_test, y_pred, labels=[cls], average='micro', zero_division=0)\n",
    "    auc_cls = roc_auc_score((y_test == cls).astype(int), model.predict_proba(X_test)[:, cls])\n",
    "\n",
    "    metrics_by_class.append({\n",
    "        'Classe': cls,\n",
    "        'Accuracy': acc_cls,\n",
    "        'Precision': precision_cls,\n",
    "        'Recall': recall_cls,\n",
    "        'F1 Macro': f1_macro_cls,\n",
    "        'F1 Micro': f1_micro_cls,\n",
    "        'AUC': auc_cls\n",
    "    })\n",
    "\n",
    "# Ajouter les m√©triques globales\n",
    "metrics_by_class.append({\n",
    "    'Classe': 'Global',\n",
    "    'Accuracy': accuracy_global,\n",
    "    'Precision': precision_global,\n",
    "    'Recall': recall_global,\n",
    "    'F1 Macro': f1_macro_global,\n",
    "    'F1 Micro': f1_micro_global,\n",
    "    'AUC': 'N/A'  # AUC globale n'est pas calcul√©e ici\n",
    "})\n",
    "\n",
    "# Affichage des m√©triques dans un tableau\n",
    "df_metrics = pd.DataFrame(metrics_by_class)\n",
    "df_metrics.set_index('Classe', inplace=True)\n",
    "\n",
    "print(\"\\nüìä M√©triques par classe + Globales :\")\n",
    "print(df_metrics.round(4))\n",
    "\n",
    "# === Matrice de confusion ===\n",
    "print(\"üßæ √âtape 9 : Affichage de la matrice de confusion...\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"üìä Matrice de Confusion\")\n",
    "plt.xlabel(\"Pr√©dit\")\n",
    "plt.ylabel(\"R√©el\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Courbes ROC ===\n",
    "print(\"üìâ √âtape 10 : G√©n√©ration des courbes ROC pour les deux classes...\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for cls in classes:\n",
    "    fpr, tpr, _ = roc_curve((y_test == cls).astype(int), model.predict_proba(X_test)[:, cls])\n",
    "    auc_cls = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Classe {cls} (AUC = {auc_cls:.2f})')\n",
    "\n",
    "# Ajouter la ligne al√©atoire\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--', label='Al√©atoire')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('üìà Courbes ROC - Classification Binaire')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
